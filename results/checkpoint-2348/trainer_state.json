{
  "best_metric": 0.1866045445203781,
  "best_model_checkpoint": "./results/checkpoint-1174",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 2348,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017035775127768313,
      "grad_norm": 25.413246154785156,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.7088,
      "step": 10
    },
    {
      "epoch": 0.034071550255536626,
      "grad_norm": 5.0334696769714355,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.6676,
      "step": 20
    },
    {
      "epoch": 0.05110732538330494,
      "grad_norm": 23.984928131103516,
      "learning_rate": 3e-06,
      "loss": 0.6364,
      "step": 30
    },
    {
      "epoch": 0.06814310051107325,
      "grad_norm": 7.888204097747803,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.6578,
      "step": 40
    },
    {
      "epoch": 0.08517887563884156,
      "grad_norm": 32.37797546386719,
      "learning_rate": 5e-06,
      "loss": 0.6598,
      "step": 50
    },
    {
      "epoch": 0.10221465076660988,
      "grad_norm": 38.651756286621094,
      "learning_rate": 6e-06,
      "loss": 0.6134,
      "step": 60
    },
    {
      "epoch": 0.11925042589437819,
      "grad_norm": 12.007330894470215,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.6098,
      "step": 70
    },
    {
      "epoch": 0.1362862010221465,
      "grad_norm": 11.122819900512695,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.56,
      "step": 80
    },
    {
      "epoch": 0.15332197614991483,
      "grad_norm": 12.128156661987305,
      "learning_rate": 9e-06,
      "loss": 0.4977,
      "step": 90
    },
    {
      "epoch": 0.17035775127768313,
      "grad_norm": 25.510513305664062,
      "learning_rate": 1e-05,
      "loss": 0.4945,
      "step": 100
    },
    {
      "epoch": 0.18739352640545145,
      "grad_norm": 13.6084623336792,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.4401,
      "step": 110
    },
    {
      "epoch": 0.20442930153321975,
      "grad_norm": 8.952701568603516,
      "learning_rate": 1.2e-05,
      "loss": 0.3931,
      "step": 120
    },
    {
      "epoch": 0.22146507666098808,
      "grad_norm": 22.57946014404297,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.3563,
      "step": 130
    },
    {
      "epoch": 0.23850085178875638,
      "grad_norm": 8.835784912109375,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.3205,
      "step": 140
    },
    {
      "epoch": 0.2555366269165247,
      "grad_norm": 13.787555694580078,
      "learning_rate": 1.5e-05,
      "loss": 0.3158,
      "step": 150
    },
    {
      "epoch": 0.272572402044293,
      "grad_norm": 16.85650062561035,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.3612,
      "step": 160
    },
    {
      "epoch": 0.28960817717206133,
      "grad_norm": 13.126489639282227,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.314,
      "step": 170
    },
    {
      "epoch": 0.30664395229982966,
      "grad_norm": 12.934821128845215,
      "learning_rate": 1.8e-05,
      "loss": 0.3747,
      "step": 180
    },
    {
      "epoch": 0.32367972742759793,
      "grad_norm": 12.16745376586914,
      "learning_rate": 1.9e-05,
      "loss": 0.291,
      "step": 190
    },
    {
      "epoch": 0.34071550255536626,
      "grad_norm": 4.801584243774414,
      "learning_rate": 2e-05,
      "loss": 0.2275,
      "step": 200
    },
    {
      "epoch": 0.3577512776831346,
      "grad_norm": 27.55113983154297,
      "learning_rate": 2.1e-05,
      "loss": 0.3203,
      "step": 210
    },
    {
      "epoch": 0.3747870528109029,
      "grad_norm": 11.616288185119629,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.2229,
      "step": 220
    },
    {
      "epoch": 0.39182282793867124,
      "grad_norm": 36.76420211791992,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.3511,
      "step": 230
    },
    {
      "epoch": 0.4088586030664395,
      "grad_norm": 13.19442081451416,
      "learning_rate": 2.4e-05,
      "loss": 0.2595,
      "step": 240
    },
    {
      "epoch": 0.42589437819420783,
      "grad_norm": 13.202888488769531,
      "learning_rate": 2.5e-05,
      "loss": 0.2905,
      "step": 250
    },
    {
      "epoch": 0.44293015332197616,
      "grad_norm": 6.731511116027832,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.2165,
      "step": 260
    },
    {
      "epoch": 0.4599659284497445,
      "grad_norm": 7.616877555847168,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.2502,
      "step": 270
    },
    {
      "epoch": 0.47700170357751276,
      "grad_norm": 7.462326526641846,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.298,
      "step": 280
    },
    {
      "epoch": 0.4940374787052811,
      "grad_norm": 20.823688507080078,
      "learning_rate": 2.9e-05,
      "loss": 0.2699,
      "step": 290
    },
    {
      "epoch": 0.5110732538330494,
      "grad_norm": 15.519115447998047,
      "learning_rate": 3e-05,
      "loss": 0.1822,
      "step": 300
    },
    {
      "epoch": 0.5281090289608177,
      "grad_norm": 12.075932502746582,
      "learning_rate": 3.1e-05,
      "loss": 0.253,
      "step": 310
    },
    {
      "epoch": 0.545144804088586,
      "grad_norm": 15.921222686767578,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.2721,
      "step": 320
    },
    {
      "epoch": 0.5621805792163543,
      "grad_norm": 12.773136138916016,
      "learning_rate": 3.3e-05,
      "loss": 0.2178,
      "step": 330
    },
    {
      "epoch": 0.5792163543441227,
      "grad_norm": 21.427610397338867,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.2079,
      "step": 340
    },
    {
      "epoch": 0.596252129471891,
      "grad_norm": 12.651578903198242,
      "learning_rate": 3.5e-05,
      "loss": 0.1557,
      "step": 350
    },
    {
      "epoch": 0.6132879045996593,
      "grad_norm": 36.55511474609375,
      "learning_rate": 3.6e-05,
      "loss": 0.3406,
      "step": 360
    },
    {
      "epoch": 0.6303236797274276,
      "grad_norm": 2.4123647212982178,
      "learning_rate": 3.7e-05,
      "loss": 0.1693,
      "step": 370
    },
    {
      "epoch": 0.6473594548551959,
      "grad_norm": 5.229705810546875,
      "learning_rate": 3.8e-05,
      "loss": 0.2639,
      "step": 380
    },
    {
      "epoch": 0.6643952299829642,
      "grad_norm": 11.200862884521484,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.2857,
      "step": 390
    },
    {
      "epoch": 0.6814310051107325,
      "grad_norm": 9.153830528259277,
      "learning_rate": 4e-05,
      "loss": 0.1775,
      "step": 400
    },
    {
      "epoch": 0.6984667802385008,
      "grad_norm": 14.036727905273438,
      "learning_rate": 4.1e-05,
      "loss": 0.1968,
      "step": 410
    },
    {
      "epoch": 0.7155025553662692,
      "grad_norm": 5.338423728942871,
      "learning_rate": 4.2e-05,
      "loss": 0.0889,
      "step": 420
    },
    {
      "epoch": 0.7325383304940375,
      "grad_norm": 18.98155403137207,
      "learning_rate": 4.3e-05,
      "loss": 0.1384,
      "step": 430
    },
    {
      "epoch": 0.7495741056218058,
      "grad_norm": 12.67285442352295,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.2719,
      "step": 440
    },
    {
      "epoch": 0.7666098807495741,
      "grad_norm": 9.957271575927734,
      "learning_rate": 4.5e-05,
      "loss": 0.2006,
      "step": 450
    },
    {
      "epoch": 0.7836456558773425,
      "grad_norm": 22.82381820678711,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.2733,
      "step": 460
    },
    {
      "epoch": 0.8006814310051107,
      "grad_norm": 5.312160491943359,
      "learning_rate": 4.7e-05,
      "loss": 0.2693,
      "step": 470
    },
    {
      "epoch": 0.817717206132879,
      "grad_norm": 1.9658080339431763,
      "learning_rate": 4.8e-05,
      "loss": 0.1986,
      "step": 480
    },
    {
      "epoch": 0.8347529812606473,
      "grad_norm": 12.124688148498535,
      "learning_rate": 4.9e-05,
      "loss": 0.2834,
      "step": 490
    },
    {
      "epoch": 0.8517887563884157,
      "grad_norm": 14.122841835021973,
      "learning_rate": 5e-05,
      "loss": 0.1611,
      "step": 500
    },
    {
      "epoch": 0.868824531516184,
      "grad_norm": 10.702557563781738,
      "learning_rate": 4.9794661190965095e-05,
      "loss": 0.169,
      "step": 510
    },
    {
      "epoch": 0.8858603066439523,
      "grad_norm": 46.47195053100586,
      "learning_rate": 4.958932238193019e-05,
      "loss": 0.2353,
      "step": 520
    },
    {
      "epoch": 0.9028960817717206,
      "grad_norm": 10.001605033874512,
      "learning_rate": 4.938398357289528e-05,
      "loss": 0.3345,
      "step": 530
    },
    {
      "epoch": 0.919931856899489,
      "grad_norm": 16.140180587768555,
      "learning_rate": 4.9178644763860374e-05,
      "loss": 0.1891,
      "step": 540
    },
    {
      "epoch": 0.9369676320272572,
      "grad_norm": 30.681995391845703,
      "learning_rate": 4.897330595482547e-05,
      "loss": 0.4083,
      "step": 550
    },
    {
      "epoch": 0.9540034071550255,
      "grad_norm": 2.721730947494507,
      "learning_rate": 4.876796714579055e-05,
      "loss": 0.1998,
      "step": 560
    },
    {
      "epoch": 0.9710391822827938,
      "grad_norm": 26.55730438232422,
      "learning_rate": 4.856262833675565e-05,
      "loss": 0.2245,
      "step": 570
    },
    {
      "epoch": 0.9880749574105622,
      "grad_norm": 2.1997463703155518,
      "learning_rate": 4.835728952772074e-05,
      "loss": 0.1924,
      "step": 580
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.2695698142051697,
      "eval_runtime": 5.753,
      "eval_samples_per_second": 181.297,
      "eval_steps_per_second": 11.472,
      "step": 587
    },
    {
      "epoch": 1.0051107325383304,
      "grad_norm": 4.964422702789307,
      "learning_rate": 4.815195071868583e-05,
      "loss": 0.1274,
      "step": 590
    },
    {
      "epoch": 1.0221465076660987,
      "grad_norm": 16.800622940063477,
      "learning_rate": 4.7946611909650925e-05,
      "loss": 0.1116,
      "step": 600
    },
    {
      "epoch": 1.039182282793867,
      "grad_norm": 0.9225417971611023,
      "learning_rate": 4.774127310061602e-05,
      "loss": 0.2819,
      "step": 610
    },
    {
      "epoch": 1.0562180579216354,
      "grad_norm": 15.590559005737305,
      "learning_rate": 4.753593429158111e-05,
      "loss": 0.2203,
      "step": 620
    },
    {
      "epoch": 1.0732538330494037,
      "grad_norm": 4.365182399749756,
      "learning_rate": 4.73305954825462e-05,
      "loss": 0.3106,
      "step": 630
    },
    {
      "epoch": 1.090289608177172,
      "grad_norm": 3.0326333045959473,
      "learning_rate": 4.7125256673511296e-05,
      "loss": 0.1003,
      "step": 640
    },
    {
      "epoch": 1.1073253833049403,
      "grad_norm": 14.64756965637207,
      "learning_rate": 4.691991786447639e-05,
      "loss": 0.0788,
      "step": 650
    },
    {
      "epoch": 1.1243611584327087,
      "grad_norm": 12.733439445495605,
      "learning_rate": 4.671457905544148e-05,
      "loss": 0.111,
      "step": 660
    },
    {
      "epoch": 1.141396933560477,
      "grad_norm": 6.224941253662109,
      "learning_rate": 4.650924024640657e-05,
      "loss": 0.2882,
      "step": 670
    },
    {
      "epoch": 1.1584327086882453,
      "grad_norm": 30.02115821838379,
      "learning_rate": 4.630390143737167e-05,
      "loss": 0.3366,
      "step": 680
    },
    {
      "epoch": 1.1754684838160137,
      "grad_norm": 11.013795852661133,
      "learning_rate": 4.6098562628336754e-05,
      "loss": 0.2755,
      "step": 690
    },
    {
      "epoch": 1.192504258943782,
      "grad_norm": 6.486360549926758,
      "learning_rate": 4.5893223819301853e-05,
      "loss": 0.3332,
      "step": 700
    },
    {
      "epoch": 1.2095400340715503,
      "grad_norm": 13.706768989562988,
      "learning_rate": 4.5687885010266946e-05,
      "loss": 0.2473,
      "step": 710
    },
    {
      "epoch": 1.2265758091993186,
      "grad_norm": 1.5129573345184326,
      "learning_rate": 4.548254620123203e-05,
      "loss": 0.1354,
      "step": 720
    },
    {
      "epoch": 1.243611584327087,
      "grad_norm": 23.070661544799805,
      "learning_rate": 4.527720739219713e-05,
      "loss": 0.2551,
      "step": 730
    },
    {
      "epoch": 1.2606473594548553,
      "grad_norm": 7.986393451690674,
      "learning_rate": 4.507186858316222e-05,
      "loss": 0.1,
      "step": 740
    },
    {
      "epoch": 1.2776831345826234,
      "grad_norm": 0.466872900724411,
      "learning_rate": 4.486652977412731e-05,
      "loss": 0.2082,
      "step": 750
    },
    {
      "epoch": 1.294718909710392,
      "grad_norm": 10.607793807983398,
      "learning_rate": 4.4661190965092404e-05,
      "loss": 0.198,
      "step": 760
    },
    {
      "epoch": 1.31175468483816,
      "grad_norm": 26.645593643188477,
      "learning_rate": 4.44558521560575e-05,
      "loss": 0.2364,
      "step": 770
    },
    {
      "epoch": 1.3287904599659284,
      "grad_norm": 14.825064659118652,
      "learning_rate": 4.425051334702259e-05,
      "loss": 0.1269,
      "step": 780
    },
    {
      "epoch": 1.3458262350936967,
      "grad_norm": 8.223283767700195,
      "learning_rate": 4.404517453798768e-05,
      "loss": 0.1317,
      "step": 790
    },
    {
      "epoch": 1.362862010221465,
      "grad_norm": 7.748399257659912,
      "learning_rate": 4.383983572895277e-05,
      "loss": 0.0816,
      "step": 800
    },
    {
      "epoch": 1.3798977853492334,
      "grad_norm": 19.56467628479004,
      "learning_rate": 4.363449691991787e-05,
      "loss": 0.1842,
      "step": 810
    },
    {
      "epoch": 1.3969335604770017,
      "grad_norm": 17.150074005126953,
      "learning_rate": 4.342915811088296e-05,
      "loss": 0.3351,
      "step": 820
    },
    {
      "epoch": 1.41396933560477,
      "grad_norm": 13.438773155212402,
      "learning_rate": 4.322381930184805e-05,
      "loss": 0.1902,
      "step": 830
    },
    {
      "epoch": 1.4310051107325383,
      "grad_norm": 11.66453742980957,
      "learning_rate": 4.301848049281315e-05,
      "loss": 0.1721,
      "step": 840
    },
    {
      "epoch": 1.4480408858603067,
      "grad_norm": 5.700105667114258,
      "learning_rate": 4.281314168377823e-05,
      "loss": 0.2077,
      "step": 850
    },
    {
      "epoch": 1.465076660988075,
      "grad_norm": 6.155858993530273,
      "learning_rate": 4.260780287474333e-05,
      "loss": 0.1258,
      "step": 860
    },
    {
      "epoch": 1.4821124361158433,
      "grad_norm": 22.04336929321289,
      "learning_rate": 4.240246406570842e-05,
      "loss": 0.1688,
      "step": 870
    },
    {
      "epoch": 1.4991482112436116,
      "grad_norm": 11.554489135742188,
      "learning_rate": 4.219712525667351e-05,
      "loss": 0.1036,
      "step": 880
    },
    {
      "epoch": 1.51618398637138,
      "grad_norm": 4.159140110015869,
      "learning_rate": 4.1991786447638605e-05,
      "loss": 0.1574,
      "step": 890
    },
    {
      "epoch": 1.533219761499148,
      "grad_norm": 24.877073287963867,
      "learning_rate": 4.17864476386037e-05,
      "loss": 0.1391,
      "step": 900
    },
    {
      "epoch": 1.5502555366269166,
      "grad_norm": 6.407093048095703,
      "learning_rate": 4.158110882956879e-05,
      "loss": 0.101,
      "step": 910
    },
    {
      "epoch": 1.5672913117546847,
      "grad_norm": 2.5756213665008545,
      "learning_rate": 4.1375770020533884e-05,
      "loss": 0.3268,
      "step": 920
    },
    {
      "epoch": 1.5843270868824533,
      "grad_norm": 7.925332546234131,
      "learning_rate": 4.1170431211498976e-05,
      "loss": 0.1555,
      "step": 930
    },
    {
      "epoch": 1.6013628620102214,
      "grad_norm": 5.452301502227783,
      "learning_rate": 4.096509240246407e-05,
      "loss": 0.1955,
      "step": 940
    },
    {
      "epoch": 1.61839863713799,
      "grad_norm": 3.178297758102417,
      "learning_rate": 4.075975359342916e-05,
      "loss": 0.2216,
      "step": 950
    },
    {
      "epoch": 1.635434412265758,
      "grad_norm": 9.635289192199707,
      "learning_rate": 4.055441478439425e-05,
      "loss": 0.2231,
      "step": 960
    },
    {
      "epoch": 1.6524701873935264,
      "grad_norm": 6.953661918640137,
      "learning_rate": 4.034907597535935e-05,
      "loss": 0.2217,
      "step": 970
    },
    {
      "epoch": 1.6695059625212947,
      "grad_norm": 7.167145729064941,
      "learning_rate": 4.0143737166324434e-05,
      "loss": 0.1382,
      "step": 980
    },
    {
      "epoch": 1.686541737649063,
      "grad_norm": 13.41245174407959,
      "learning_rate": 3.993839835728953e-05,
      "loss": 0.2039,
      "step": 990
    },
    {
      "epoch": 1.7035775127768313,
      "grad_norm": 5.088326454162598,
      "learning_rate": 3.973305954825462e-05,
      "loss": 0.161,
      "step": 1000
    },
    {
      "epoch": 1.7206132879045997,
      "grad_norm": 2.271005868911743,
      "learning_rate": 3.952772073921971e-05,
      "loss": 0.1584,
      "step": 1010
    },
    {
      "epoch": 1.737649063032368,
      "grad_norm": 1.8039469718933105,
      "learning_rate": 3.932238193018481e-05,
      "loss": 0.1429,
      "step": 1020
    },
    {
      "epoch": 1.7546848381601363,
      "grad_norm": 0.933830738067627,
      "learning_rate": 3.91170431211499e-05,
      "loss": 0.1089,
      "step": 1030
    },
    {
      "epoch": 1.7717206132879046,
      "grad_norm": 9.497044563293457,
      "learning_rate": 3.891170431211499e-05,
      "loss": 0.0768,
      "step": 1040
    },
    {
      "epoch": 1.7887563884156727,
      "grad_norm": 0.7321650385856628,
      "learning_rate": 3.8706365503080084e-05,
      "loss": 0.2048,
      "step": 1050
    },
    {
      "epoch": 1.8057921635434413,
      "grad_norm": 10.863763809204102,
      "learning_rate": 3.850102669404518e-05,
      "loss": 0.0886,
      "step": 1060
    },
    {
      "epoch": 1.8228279386712094,
      "grad_norm": 5.1400933265686035,
      "learning_rate": 3.829568788501027e-05,
      "loss": 0.2184,
      "step": 1070
    },
    {
      "epoch": 1.839863713798978,
      "grad_norm": 31.674211502075195,
      "learning_rate": 3.809034907597536e-05,
      "loss": 0.1868,
      "step": 1080
    },
    {
      "epoch": 1.856899488926746,
      "grad_norm": 14.411787033081055,
      "learning_rate": 3.788501026694045e-05,
      "loss": 0.3162,
      "step": 1090
    },
    {
      "epoch": 1.8739352640545146,
      "grad_norm": 30.01332664489746,
      "learning_rate": 3.767967145790555e-05,
      "loss": 0.3645,
      "step": 1100
    },
    {
      "epoch": 1.8909710391822827,
      "grad_norm": 26.927335739135742,
      "learning_rate": 3.7474332648870635e-05,
      "loss": 0.1468,
      "step": 1110
    },
    {
      "epoch": 1.9080068143100513,
      "grad_norm": 32.019126892089844,
      "learning_rate": 3.726899383983573e-05,
      "loss": 0.1956,
      "step": 1120
    },
    {
      "epoch": 1.9250425894378194,
      "grad_norm": 4.114017009735107,
      "learning_rate": 3.706365503080083e-05,
      "loss": 0.1076,
      "step": 1130
    },
    {
      "epoch": 1.9420783645655877,
      "grad_norm": 27.222002029418945,
      "learning_rate": 3.6858316221765914e-05,
      "loss": 0.2004,
      "step": 1140
    },
    {
      "epoch": 1.959114139693356,
      "grad_norm": 17.27719497680664,
      "learning_rate": 3.6652977412731007e-05,
      "loss": 0.1522,
      "step": 1150
    },
    {
      "epoch": 1.9761499148211243,
      "grad_norm": 6.924071311950684,
      "learning_rate": 3.64476386036961e-05,
      "loss": 0.1028,
      "step": 1160
    },
    {
      "epoch": 1.9931856899488927,
      "grad_norm": 17.161296844482422,
      "learning_rate": 3.624229979466119e-05,
      "loss": 0.142,
      "step": 1170
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.1866045445203781,
      "eval_runtime": 5.9837,
      "eval_samples_per_second": 174.308,
      "eval_steps_per_second": 11.03,
      "step": 1174
    },
    {
      "epoch": 2.0102214650766608,
      "grad_norm": 8.86362075805664,
      "learning_rate": 3.6036960985626285e-05,
      "loss": 0.1322,
      "step": 1180
    },
    {
      "epoch": 2.0272572402044293,
      "grad_norm": 1.6972591876983643,
      "learning_rate": 3.583162217659138e-05,
      "loss": 0.0982,
      "step": 1190
    },
    {
      "epoch": 2.0442930153321974,
      "grad_norm": 0.6187973618507385,
      "learning_rate": 3.562628336755647e-05,
      "loss": 0.0288,
      "step": 1200
    },
    {
      "epoch": 2.061328790459966,
      "grad_norm": 11.010302543640137,
      "learning_rate": 3.5420944558521564e-05,
      "loss": 0.1088,
      "step": 1210
    },
    {
      "epoch": 2.078364565587734,
      "grad_norm": 0.3715757727622986,
      "learning_rate": 3.521560574948665e-05,
      "loss": 0.1529,
      "step": 1220
    },
    {
      "epoch": 2.0954003407155026,
      "grad_norm": 20.157926559448242,
      "learning_rate": 3.501026694045175e-05,
      "loss": 0.1077,
      "step": 1230
    },
    {
      "epoch": 2.1124361158432707,
      "grad_norm": 3.9451003074645996,
      "learning_rate": 3.480492813141684e-05,
      "loss": 0.1297,
      "step": 1240
    },
    {
      "epoch": 2.1294718909710393,
      "grad_norm": 4.541410446166992,
      "learning_rate": 3.459958932238193e-05,
      "loss": 0.1805,
      "step": 1250
    },
    {
      "epoch": 2.1465076660988074,
      "grad_norm": 20.80743408203125,
      "learning_rate": 3.439425051334703e-05,
      "loss": 0.2195,
      "step": 1260
    },
    {
      "epoch": 2.163543441226576,
      "grad_norm": 6.777219295501709,
      "learning_rate": 3.4188911704312115e-05,
      "loss": 0.175,
      "step": 1270
    },
    {
      "epoch": 2.180579216354344,
      "grad_norm": 0.17434127628803253,
      "learning_rate": 3.398357289527721e-05,
      "loss": 0.1219,
      "step": 1280
    },
    {
      "epoch": 2.1976149914821126,
      "grad_norm": 18.978322982788086,
      "learning_rate": 3.37782340862423e-05,
      "loss": 0.1046,
      "step": 1290
    },
    {
      "epoch": 2.2146507666098807,
      "grad_norm": 0.6421937346458435,
      "learning_rate": 3.357289527720739e-05,
      "loss": 0.0632,
      "step": 1300
    },
    {
      "epoch": 2.2316865417376492,
      "grad_norm": 1.07965886592865,
      "learning_rate": 3.3367556468172486e-05,
      "loss": 0.1463,
      "step": 1310
    },
    {
      "epoch": 2.2487223168654173,
      "grad_norm": 1.2810826301574707,
      "learning_rate": 3.316221765913758e-05,
      "loss": 0.0793,
      "step": 1320
    },
    {
      "epoch": 2.2657580919931855,
      "grad_norm": 0.3480106294155121,
      "learning_rate": 3.295687885010267e-05,
      "loss": 0.2073,
      "step": 1330
    },
    {
      "epoch": 2.282793867120954,
      "grad_norm": 0.771982729434967,
      "learning_rate": 3.2751540041067765e-05,
      "loss": 0.0968,
      "step": 1340
    },
    {
      "epoch": 2.2998296422487225,
      "grad_norm": 14.478982925415039,
      "learning_rate": 3.254620123203286e-05,
      "loss": 0.1568,
      "step": 1350
    },
    {
      "epoch": 2.3168654173764907,
      "grad_norm": 0.16207166016101837,
      "learning_rate": 3.234086242299795e-05,
      "loss": 0.1277,
      "step": 1360
    },
    {
      "epoch": 2.3339011925042588,
      "grad_norm": 0.6609575152397156,
      "learning_rate": 3.2135523613963043e-05,
      "loss": 0.1004,
      "step": 1370
    },
    {
      "epoch": 2.3509369676320273,
      "grad_norm": 8.052802085876465,
      "learning_rate": 3.193018480492813e-05,
      "loss": 0.1331,
      "step": 1380
    },
    {
      "epoch": 2.3679727427597954,
      "grad_norm": 0.9639655947685242,
      "learning_rate": 3.172484599589323e-05,
      "loss": 0.1214,
      "step": 1390
    },
    {
      "epoch": 2.385008517887564,
      "grad_norm": 12.276825904846191,
      "learning_rate": 3.1519507186858315e-05,
      "loss": 0.146,
      "step": 1400
    },
    {
      "epoch": 2.402044293015332,
      "grad_norm": 5.588064193725586,
      "learning_rate": 3.131416837782341e-05,
      "loss": 0.0325,
      "step": 1410
    },
    {
      "epoch": 2.4190800681431006,
      "grad_norm": 0.23942013084888458,
      "learning_rate": 3.11088295687885e-05,
      "loss": 0.0317,
      "step": 1420
    },
    {
      "epoch": 2.4361158432708687,
      "grad_norm": 3.9552135467529297,
      "learning_rate": 3.0903490759753594e-05,
      "loss": 0.1393,
      "step": 1430
    },
    {
      "epoch": 2.4531516183986373,
      "grad_norm": 10.020195007324219,
      "learning_rate": 3.069815195071869e-05,
      "loss": 0.1208,
      "step": 1440
    },
    {
      "epoch": 2.4701873935264054,
      "grad_norm": 1.9292117357254028,
      "learning_rate": 3.049281314168378e-05,
      "loss": 0.0904,
      "step": 1450
    },
    {
      "epoch": 2.487223168654174,
      "grad_norm": 16.16533088684082,
      "learning_rate": 3.0287474332648873e-05,
      "loss": 0.148,
      "step": 1460
    },
    {
      "epoch": 2.504258943781942,
      "grad_norm": 16.99977684020996,
      "learning_rate": 3.0082135523613962e-05,
      "loss": 0.3847,
      "step": 1470
    },
    {
      "epoch": 2.5212947189097106,
      "grad_norm": 17.284812927246094,
      "learning_rate": 2.987679671457906e-05,
      "loss": 0.1371,
      "step": 1480
    },
    {
      "epoch": 2.5383304940374787,
      "grad_norm": 12.707640647888184,
      "learning_rate": 2.9671457905544148e-05,
      "loss": 0.0469,
      "step": 1490
    },
    {
      "epoch": 2.555366269165247,
      "grad_norm": 10.867521286010742,
      "learning_rate": 2.9466119096509244e-05,
      "loss": 0.1672,
      "step": 1500
    },
    {
      "epoch": 2.5724020442930153,
      "grad_norm": 1.2734743356704712,
      "learning_rate": 2.926078028747433e-05,
      "loss": 0.104,
      "step": 1510
    },
    {
      "epoch": 2.589437819420784,
      "grad_norm": 7.7752790451049805,
      "learning_rate": 2.9055441478439427e-05,
      "loss": 0.0766,
      "step": 1520
    },
    {
      "epoch": 2.606473594548552,
      "grad_norm": 0.6188757419586182,
      "learning_rate": 2.8850102669404516e-05,
      "loss": 0.1255,
      "step": 1530
    },
    {
      "epoch": 2.62350936967632,
      "grad_norm": 12.681361198425293,
      "learning_rate": 2.8644763860369613e-05,
      "loss": 0.0897,
      "step": 1540
    },
    {
      "epoch": 2.6405451448040886,
      "grad_norm": 0.19168348610401154,
      "learning_rate": 2.8439425051334705e-05,
      "loss": 0.072,
      "step": 1550
    },
    {
      "epoch": 2.6575809199318567,
      "grad_norm": 0.11527244001626968,
      "learning_rate": 2.8234086242299795e-05,
      "loss": 0.155,
      "step": 1560
    },
    {
      "epoch": 2.6746166950596253,
      "grad_norm": 7.027371883392334,
      "learning_rate": 2.802874743326489e-05,
      "loss": 0.1206,
      "step": 1570
    },
    {
      "epoch": 2.6916524701873934,
      "grad_norm": 34.653526306152344,
      "learning_rate": 2.782340862422998e-05,
      "loss": 0.1399,
      "step": 1580
    },
    {
      "epoch": 2.708688245315162,
      "grad_norm": 5.4252190589904785,
      "learning_rate": 2.7618069815195074e-05,
      "loss": 0.167,
      "step": 1590
    },
    {
      "epoch": 2.72572402044293,
      "grad_norm": 5.312686920166016,
      "learning_rate": 2.7412731006160163e-05,
      "loss": 0.1598,
      "step": 1600
    },
    {
      "epoch": 2.7427597955706986,
      "grad_norm": 9.151183128356934,
      "learning_rate": 2.720739219712526e-05,
      "loss": 0.1306,
      "step": 1610
    },
    {
      "epoch": 2.7597955706984667,
      "grad_norm": 14.28853702545166,
      "learning_rate": 2.700205338809035e-05,
      "loss": 0.1106,
      "step": 1620
    },
    {
      "epoch": 2.7768313458262353,
      "grad_norm": 1.441367268562317,
      "learning_rate": 2.6796714579055442e-05,
      "loss": 0.062,
      "step": 1630
    },
    {
      "epoch": 2.7938671209540034,
      "grad_norm": 12.48198127746582,
      "learning_rate": 2.6591375770020538e-05,
      "loss": 0.1632,
      "step": 1640
    },
    {
      "epoch": 2.810902896081772,
      "grad_norm": 0.09869640320539474,
      "learning_rate": 2.6386036960985628e-05,
      "loss": 0.0707,
      "step": 1650
    },
    {
      "epoch": 2.82793867120954,
      "grad_norm": 8.732521057128906,
      "learning_rate": 2.6180698151950724e-05,
      "loss": 0.0356,
      "step": 1660
    },
    {
      "epoch": 2.844974446337308,
      "grad_norm": 0.049738239496946335,
      "learning_rate": 2.597535934291581e-05,
      "loss": 0.044,
      "step": 1670
    },
    {
      "epoch": 2.8620102214650767,
      "grad_norm": 23.181055068969727,
      "learning_rate": 2.5770020533880906e-05,
      "loss": 0.2314,
      "step": 1680
    },
    {
      "epoch": 2.879045996592845,
      "grad_norm": 10.467681884765625,
      "learning_rate": 2.5564681724845996e-05,
      "loss": 0.1303,
      "step": 1690
    },
    {
      "epoch": 2.8960817717206133,
      "grad_norm": 8.715301513671875,
      "learning_rate": 2.5359342915811092e-05,
      "loss": 0.0865,
      "step": 1700
    },
    {
      "epoch": 2.9131175468483814,
      "grad_norm": 19.798545837402344,
      "learning_rate": 2.515400410677618e-05,
      "loss": 0.1287,
      "step": 1710
    },
    {
      "epoch": 2.93015332197615,
      "grad_norm": 6.250337600708008,
      "learning_rate": 2.4948665297741274e-05,
      "loss": 0.1449,
      "step": 1720
    },
    {
      "epoch": 2.947189097103918,
      "grad_norm": 6.787060260772705,
      "learning_rate": 2.4743326488706367e-05,
      "loss": 0.0339,
      "step": 1730
    },
    {
      "epoch": 2.9642248722316866,
      "grad_norm": 0.5556516051292419,
      "learning_rate": 2.453798767967146e-05,
      "loss": 0.0862,
      "step": 1740
    },
    {
      "epoch": 2.9812606473594547,
      "grad_norm": 2.748883008956909,
      "learning_rate": 2.433264887063655e-05,
      "loss": 0.0631,
      "step": 1750
    },
    {
      "epoch": 2.9982964224872233,
      "grad_norm": 3.478654623031616,
      "learning_rate": 2.4127310061601643e-05,
      "loss": 0.1123,
      "step": 1760
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.23993761837482452,
      "eval_runtime": 5.7675,
      "eval_samples_per_second": 180.84,
      "eval_steps_per_second": 11.443,
      "step": 1761
    },
    {
      "epoch": 3.0153321976149914,
      "grad_norm": 0.054369308054447174,
      "learning_rate": 2.3921971252566736e-05,
      "loss": 0.132,
      "step": 1770
    },
    {
      "epoch": 3.03236797274276,
      "grad_norm": 8.680726051330566,
      "learning_rate": 2.371663244353183e-05,
      "loss": 0.017,
      "step": 1780
    },
    {
      "epoch": 3.049403747870528,
      "grad_norm": 13.867537498474121,
      "learning_rate": 2.351129363449692e-05,
      "loss": 0.0916,
      "step": 1790
    },
    {
      "epoch": 3.0664395229982966,
      "grad_norm": 15.339571952819824,
      "learning_rate": 2.3305954825462014e-05,
      "loss": 0.066,
      "step": 1800
    },
    {
      "epoch": 3.0834752981260647,
      "grad_norm": 0.1826847493648529,
      "learning_rate": 2.3100616016427107e-05,
      "loss": 0.1029,
      "step": 1810
    },
    {
      "epoch": 3.1005110732538332,
      "grad_norm": 0.8598243594169617,
      "learning_rate": 2.28952772073922e-05,
      "loss": 0.0704,
      "step": 1820
    },
    {
      "epoch": 3.1175468483816013,
      "grad_norm": 7.104372501373291,
      "learning_rate": 2.268993839835729e-05,
      "loss": 0.0165,
      "step": 1830
    },
    {
      "epoch": 3.1345826235093694,
      "grad_norm": 16.021535873413086,
      "learning_rate": 2.2484599589322382e-05,
      "loss": 0.1105,
      "step": 1840
    },
    {
      "epoch": 3.151618398637138,
      "grad_norm": 16.73668098449707,
      "learning_rate": 2.2279260780287475e-05,
      "loss": 0.132,
      "step": 1850
    },
    {
      "epoch": 3.168654173764906,
      "grad_norm": 0.10282571613788605,
      "learning_rate": 2.2073921971252568e-05,
      "loss": 0.1199,
      "step": 1860
    },
    {
      "epoch": 3.1856899488926746,
      "grad_norm": 1.4064455032348633,
      "learning_rate": 2.186858316221766e-05,
      "loss": 0.1467,
      "step": 1870
    },
    {
      "epoch": 3.2027257240204428,
      "grad_norm": 0.12026312947273254,
      "learning_rate": 2.166324435318275e-05,
      "loss": 0.1352,
      "step": 1880
    },
    {
      "epoch": 3.2197614991482113,
      "grad_norm": 0.12873966991901398,
      "learning_rate": 2.1457905544147843e-05,
      "loss": 0.0413,
      "step": 1890
    },
    {
      "epoch": 3.2367972742759794,
      "grad_norm": 9.752646446228027,
      "learning_rate": 2.125256673511294e-05,
      "loss": 0.0901,
      "step": 1900
    },
    {
      "epoch": 3.253833049403748,
      "grad_norm": 20.139324188232422,
      "learning_rate": 2.104722792607803e-05,
      "loss": 0.0372,
      "step": 1910
    },
    {
      "epoch": 3.270868824531516,
      "grad_norm": 0.6353631615638733,
      "learning_rate": 2.0841889117043122e-05,
      "loss": 0.1411,
      "step": 1920
    },
    {
      "epoch": 3.2879045996592846,
      "grad_norm": 0.1016368567943573,
      "learning_rate": 2.0636550308008215e-05,
      "loss": 0.0357,
      "step": 1930
    },
    {
      "epoch": 3.3049403747870527,
      "grad_norm": 7.299797534942627,
      "learning_rate": 2.0431211498973308e-05,
      "loss": 0.0307,
      "step": 1940
    },
    {
      "epoch": 3.3219761499148213,
      "grad_norm": 27.214794158935547,
      "learning_rate": 2.02258726899384e-05,
      "loss": 0.0474,
      "step": 1950
    },
    {
      "epoch": 3.3390119250425894,
      "grad_norm": 0.16465355455875397,
      "learning_rate": 2.002053388090349e-05,
      "loss": 0.1448,
      "step": 1960
    },
    {
      "epoch": 3.356047700170358,
      "grad_norm": 1.4892023801803589,
      "learning_rate": 1.9815195071868583e-05,
      "loss": 0.1755,
      "step": 1970
    },
    {
      "epoch": 3.373083475298126,
      "grad_norm": 0.9304128885269165,
      "learning_rate": 1.9609856262833676e-05,
      "loss": 0.1418,
      "step": 1980
    },
    {
      "epoch": 3.3901192504258946,
      "grad_norm": 0.1385604739189148,
      "learning_rate": 1.940451745379877e-05,
      "loss": 0.0124,
      "step": 1990
    },
    {
      "epoch": 3.4071550255536627,
      "grad_norm": 0.05215208977460861,
      "learning_rate": 1.919917864476386e-05,
      "loss": 0.0903,
      "step": 2000
    },
    {
      "epoch": 3.424190800681431,
      "grad_norm": 0.5630666613578796,
      "learning_rate": 1.8993839835728955e-05,
      "loss": 0.0525,
      "step": 2010
    },
    {
      "epoch": 3.4412265758091993,
      "grad_norm": 0.9392935037612915,
      "learning_rate": 1.8788501026694048e-05,
      "loss": 0.0563,
      "step": 2020
    },
    {
      "epoch": 3.458262350936968,
      "grad_norm": 8.822245597839355,
      "learning_rate": 1.858316221765914e-05,
      "loss": 0.0616,
      "step": 2030
    },
    {
      "epoch": 3.475298126064736,
      "grad_norm": 10.739097595214844,
      "learning_rate": 1.837782340862423e-05,
      "loss": 0.1891,
      "step": 2040
    },
    {
      "epoch": 3.492333901192504,
      "grad_norm": 22.586198806762695,
      "learning_rate": 1.8172484599589323e-05,
      "loss": 0.1054,
      "step": 2050
    },
    {
      "epoch": 3.5093696763202726,
      "grad_norm": 0.10314278304576874,
      "learning_rate": 1.7967145790554416e-05,
      "loss": 0.0404,
      "step": 2060
    },
    {
      "epoch": 3.5264054514480407,
      "grad_norm": 5.750322341918945,
      "learning_rate": 1.776180698151951e-05,
      "loss": 0.0059,
      "step": 2070
    },
    {
      "epoch": 3.5434412265758093,
      "grad_norm": 0.1836467981338501,
      "learning_rate": 1.7556468172484598e-05,
      "loss": 0.0645,
      "step": 2080
    },
    {
      "epoch": 3.5604770017035774,
      "grad_norm": 0.26647093892097473,
      "learning_rate": 1.735112936344969e-05,
      "loss": 0.037,
      "step": 2090
    },
    {
      "epoch": 3.577512776831346,
      "grad_norm": 15.6812105178833,
      "learning_rate": 1.7145790554414784e-05,
      "loss": 0.0693,
      "step": 2100
    },
    {
      "epoch": 3.594548551959114,
      "grad_norm": 0.06467767059803009,
      "learning_rate": 1.694045174537988e-05,
      "loss": 0.1978,
      "step": 2110
    },
    {
      "epoch": 3.6115843270868826,
      "grad_norm": 9.392062187194824,
      "learning_rate": 1.673511293634497e-05,
      "loss": 0.0894,
      "step": 2120
    },
    {
      "epoch": 3.6286201022146507,
      "grad_norm": 1.7289304733276367,
      "learning_rate": 1.6529774127310063e-05,
      "loss": 0.0031,
      "step": 2130
    },
    {
      "epoch": 3.645655877342419,
      "grad_norm": 0.03542985022068024,
      "learning_rate": 1.6324435318275156e-05,
      "loss": 0.1032,
      "step": 2140
    },
    {
      "epoch": 3.6626916524701874,
      "grad_norm": 0.1120733842253685,
      "learning_rate": 1.611909650924025e-05,
      "loss": 0.0334,
      "step": 2150
    },
    {
      "epoch": 3.679727427597956,
      "grad_norm": 0.0502016618847847,
      "learning_rate": 1.5913757700205338e-05,
      "loss": 0.1544,
      "step": 2160
    },
    {
      "epoch": 3.696763202725724,
      "grad_norm": 0.0886579304933548,
      "learning_rate": 1.570841889117043e-05,
      "loss": 0.003,
      "step": 2170
    },
    {
      "epoch": 3.713798977853492,
      "grad_norm": 25.555889129638672,
      "learning_rate": 1.5503080082135524e-05,
      "loss": 0.168,
      "step": 2180
    },
    {
      "epoch": 3.7308347529812607,
      "grad_norm": 0.10825984179973602,
      "learning_rate": 1.5297741273100617e-05,
      "loss": 0.0858,
      "step": 2190
    },
    {
      "epoch": 3.747870528109029,
      "grad_norm": 4.0498738288879395,
      "learning_rate": 1.5092402464065708e-05,
      "loss": 0.0397,
      "step": 2200
    },
    {
      "epoch": 3.7649063032367973,
      "grad_norm": 0.08266545832157135,
      "learning_rate": 1.4887063655030802e-05,
      "loss": 0.0234,
      "step": 2210
    },
    {
      "epoch": 3.7819420783645654,
      "grad_norm": 1.0001684427261353,
      "learning_rate": 1.4681724845995895e-05,
      "loss": 0.1381,
      "step": 2220
    },
    {
      "epoch": 3.798977853492334,
      "grad_norm": 0.0709877535700798,
      "learning_rate": 1.4476386036960987e-05,
      "loss": 0.0064,
      "step": 2230
    },
    {
      "epoch": 3.816013628620102,
      "grad_norm": 0.06987600773572922,
      "learning_rate": 1.427104722792608e-05,
      "loss": 0.0128,
      "step": 2240
    },
    {
      "epoch": 3.8330494037478706,
      "grad_norm": 0.028248228132724762,
      "learning_rate": 1.406570841889117e-05,
      "loss": 0.0913,
      "step": 2250
    },
    {
      "epoch": 3.8500851788756387,
      "grad_norm": 1.9362311363220215,
      "learning_rate": 1.3860369609856264e-05,
      "loss": 0.0016,
      "step": 2260
    },
    {
      "epoch": 3.8671209540034073,
      "grad_norm": 15.116265296936035,
      "learning_rate": 1.3655030800821356e-05,
      "loss": 0.066,
      "step": 2270
    },
    {
      "epoch": 3.8841567291311754,
      "grad_norm": 0.019324325025081635,
      "learning_rate": 1.3449691991786448e-05,
      "loss": 0.0023,
      "step": 2280
    },
    {
      "epoch": 3.901192504258944,
      "grad_norm": 0.03445519879460335,
      "learning_rate": 1.324435318275154e-05,
      "loss": 0.0762,
      "step": 2290
    },
    {
      "epoch": 3.918228279386712,
      "grad_norm": 0.13154815137386322,
      "learning_rate": 1.3039014373716632e-05,
      "loss": 0.062,
      "step": 2300
    },
    {
      "epoch": 3.93526405451448,
      "grad_norm": 0.06716214120388031,
      "learning_rate": 1.2833675564681725e-05,
      "loss": 0.0137,
      "step": 2310
    },
    {
      "epoch": 3.9522998296422487,
      "grad_norm": 0.3034460246562958,
      "learning_rate": 1.262833675564682e-05,
      "loss": 0.0577,
      "step": 2320
    },
    {
      "epoch": 3.9693356047700172,
      "grad_norm": 9.368252754211426,
      "learning_rate": 1.242299794661191e-05,
      "loss": 0.0441,
      "step": 2330
    },
    {
      "epoch": 3.9863713798977853,
      "grad_norm": 0.12645897269248962,
      "learning_rate": 1.2217659137577003e-05,
      "loss": 0.0055,
      "step": 2340
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.29311785101890564,
      "eval_runtime": 5.7477,
      "eval_samples_per_second": 181.465,
      "eval_steps_per_second": 11.483,
      "step": 2348
    }
  ],
  "logging_steps": 10,
  "max_steps": 2935,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1916244217036800.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
